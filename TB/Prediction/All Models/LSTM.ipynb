{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sK15FvPvzhKV"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Y6MRnZR2hyF"
      },
      "source": [
        "train = pd.read_csv('Final_Train.csv')\n",
        "test = pd.read_csv('Final_Test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KTo_g8e20GZ"
      },
      "source": [
        "final = train.drop(['NEP Total' , 'Pediatric' , '15-24' , '25-34' , '35-44' , '45-54' , '55-64' , 'Geriatric'] , axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLqNlY-u3K6J"
      },
      "source": [
        "final = final.fillna(method ='bfill') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "719_2d1p3M02"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eJgKxcB3YEl"
      },
      "source": [
        "scaled = scaler.fit_transform(final.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lT3SunsP3eFj"
      },
      "source": [
        "scaled_df = pd.DataFrame(scaled , columns = final.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnZT-_l23jvA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "outputId": "f57b26a2-9cec-4506-85c8-ee6d312facbb"
      },
      "source": [
        "scaled_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AGRA</th>\n",
              "      <th>AIZAWL</th>\n",
              "      <th>ALAPPUZHA</th>\n",
              "      <th>ALLAHABAD</th>\n",
              "      <th>ALWAR</th>\n",
              "      <th>AMRAVATI</th>\n",
              "      <th>AMRITSAR</th>\n",
              "      <th>BATHINDA</th>\n",
              "      <th>BHARUCH</th>\n",
              "      <th>BHOPAL</th>\n",
              "      <th>BULANDSHAHR</th>\n",
              "      <th>CACHAR</th>\n",
              "      <th>CHANDIGARH</th>\n",
              "      <th>CHENNAI</th>\n",
              "      <th>CHITTOOR</th>\n",
              "      <th>COIMBATORE</th>\n",
              "      <th>CUTTACK</th>\n",
              "      <th>DAKSHINAKANNADA</th>\n",
              "      <th>DEHRADUN</th>\n",
              "      <th>DHANBAD</th>\n",
              "      <th>DIBRUGARH</th>\n",
              "      <th>DURG</th>\n",
              "      <th>EASTKHASIHILLS</th>\n",
              "      <th>ERNAKULAM</th>\n",
              "      <th>FATEHGARHSAHIB</th>\n",
              "      <th>FIROZABAD</th>\n",
              "      <th>GANJAM</th>\n",
              "      <th>GHAZIABAD</th>\n",
              "      <th>GOLAGHAT</th>\n",
              "      <th>GUNTUR</th>\n",
              "      <th>GWALIOR</th>\n",
              "      <th>HASSAN</th>\n",
              "      <th>INDORE</th>\n",
              "      <th>JABALPUR</th>\n",
              "      <th>JAIPUR</th>\n",
              "      <th>JALANDHAR</th>\n",
              "      <th>JALGAON</th>\n",
              "      <th>JAMNAGAR</th>\n",
              "      <th>JHANSI</th>\n",
              "      <th>JODHPUR</th>\n",
              "      <th>...</th>\n",
              "      <th>LUDHIANA</th>\n",
              "      <th>MADURAI</th>\n",
              "      <th>MORADABAD</th>\n",
              "      <th>NAGPUR</th>\n",
              "      <th>NASHIK</th>\n",
              "      <th>NORTHGOA</th>\n",
              "      <th>PALAKKAD</th>\n",
              "      <th>PATIALA</th>\n",
              "      <th>PUNE</th>\n",
              "      <th>RAJKOT</th>\n",
              "      <th>RANCHI</th>\n",
              "      <th>RAYAGADA</th>\n",
              "      <th>SAGAR</th>\n",
              "      <th>SALEM</th>\n",
              "      <th>SANGLI</th>\n",
              "      <th>SIRMAUR</th>\n",
              "      <th>SOLAN</th>\n",
              "      <th>SOLAPUR</th>\n",
              "      <th>SONBHADRA</th>\n",
              "      <th>SONITPUR</th>\n",
              "      <th>SOUTHGOA</th>\n",
              "      <th>SURAT</th>\n",
              "      <th>THANE</th>\n",
              "      <th>THIRUVANANTHAPURAM</th>\n",
              "      <th>VADODARA</th>\n",
              "      <th>VALSAD</th>\n",
              "      <th>VARANASI</th>\n",
              "      <th>VISAKHAPATNAM</th>\n",
              "      <th>year</th>\n",
              "      <th>quarter</th>\n",
              "      <th>rainfall</th>\n",
              "      <th>relative_humidity</th>\n",
              "      <th>average_temperature</th>\n",
              "      <th>NSP Total/ NewMicConf Total</th>\n",
              "      <th>Relapse Total</th>\n",
              "      <th>NSN Total</th>\n",
              "      <th>so2</th>\n",
              "      <th>no2</th>\n",
              "      <th>rspm</th>\n",
              "      <th>SumOfHIV_infected</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000684</td>\n",
              "      <td>0.045074</td>\n",
              "      <td>0.452561</td>\n",
              "      <td>0.232995</td>\n",
              "      <td>0.288410</td>\n",
              "      <td>0.404624</td>\n",
              "      <td>0.179833</td>\n",
              "      <td>0.041652</td>\n",
              "      <td>0.020741</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.039646</td>\n",
              "      <td>0.230408</td>\n",
              "      <td>0.845095</td>\n",
              "      <td>0.387310</td>\n",
              "      <td>0.336927</td>\n",
              "      <td>0.529865</td>\n",
              "      <td>0.169201</td>\n",
              "      <td>0.039022</td>\n",
              "      <td>0.017539</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.096985</td>\n",
              "      <td>0.843237</td>\n",
              "      <td>0.782596</td>\n",
              "      <td>0.313198</td>\n",
              "      <td>0.312668</td>\n",
              "      <td>0.368015</td>\n",
              "      <td>0.161810</td>\n",
              "      <td>0.028246</td>\n",
              "      <td>0.012578</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000210</td>\n",
              "      <td>0.488693</td>\n",
              "      <td>0.561346</td>\n",
              "      <td>0.331980</td>\n",
              "      <td>0.334232</td>\n",
              "      <td>0.332370</td>\n",
              "      <td>0.157474</td>\n",
              "      <td>0.049707</td>\n",
              "      <td>0.021652</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002314</td>\n",
              "      <td>0.189758</td>\n",
              "      <td>0.487903</td>\n",
              "      <td>0.348731</td>\n",
              "      <td>0.393531</td>\n",
              "      <td>0.349711</td>\n",
              "      <td>0.167749</td>\n",
              "      <td>0.036587</td>\n",
              "      <td>0.017993</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3367</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.041512</td>\n",
              "      <td>0.844982</td>\n",
              "      <td>0.677657</td>\n",
              "      <td>0.376142</td>\n",
              "      <td>0.331536</td>\n",
              "      <td>0.237958</td>\n",
              "      <td>0.203658</td>\n",
              "      <td>0.028486</td>\n",
              "      <td>0.006297</td>\n",
              "      <td>0.228659</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3368</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000342</td>\n",
              "      <td>0.471332</td>\n",
              "      <td>0.669981</td>\n",
              "      <td>0.448223</td>\n",
              "      <td>0.331536</td>\n",
              "      <td>0.274566</td>\n",
              "      <td>0.221259</td>\n",
              "      <td>0.034250</td>\n",
              "      <td>0.005970</td>\n",
              "      <td>0.429878</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3369</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.074690</td>\n",
              "      <td>0.674445</td>\n",
              "      <td>0.823046</td>\n",
              "      <td>0.488325</td>\n",
              "      <td>0.374663</td>\n",
              "      <td>0.220617</td>\n",
              "      <td>0.224625</td>\n",
              "      <td>0.035336</td>\n",
              "      <td>0.006500</td>\n",
              "      <td>0.289634</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3370</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.264006</td>\n",
              "      <td>0.932948</td>\n",
              "      <td>0.730432</td>\n",
              "      <td>0.449746</td>\n",
              "      <td>0.277628</td>\n",
              "      <td>0.186898</td>\n",
              "      <td>0.231585</td>\n",
              "      <td>0.035805</td>\n",
              "      <td>0.007190</td>\n",
              "      <td>0.259146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3371</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.029997</td>\n",
              "      <td>0.822549</td>\n",
              "      <td>0.671083</td>\n",
              "      <td>0.463452</td>\n",
              "      <td>0.196765</td>\n",
              "      <td>0.144509</td>\n",
              "      <td>0.229681</td>\n",
              "      <td>0.035365</td>\n",
              "      <td>0.006755</td>\n",
              "      <td>0.332317</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3372 rows Ã— 89 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      AGRA  AIZAWL  ALAPPUZHA  ...       no2      rspm  SumOfHIV_infected\n",
              "0      1.0     0.0        0.0  ...  0.041652  0.020741           0.000000\n",
              "1      1.0     0.0        0.0  ...  0.039022  0.017539           0.000000\n",
              "2      1.0     0.0        0.0  ...  0.028246  0.012578           0.000000\n",
              "3      1.0     0.0        0.0  ...  0.049707  0.021652           0.000000\n",
              "4      1.0     0.0        0.0  ...  0.036587  0.017993           0.000000\n",
              "...    ...     ...        ...  ...       ...       ...                ...\n",
              "3367   0.0     0.0        0.0  ...  0.028486  0.006297           0.228659\n",
              "3368   0.0     0.0        0.0  ...  0.034250  0.005970           0.429878\n",
              "3369   0.0     0.0        0.0  ...  0.035336  0.006500           0.289634\n",
              "3370   0.0     0.0        0.0  ...  0.035805  0.007190           0.259146\n",
              "3371   0.0     0.0        0.0  ...  0.035365  0.006755           0.332317\n",
              "\n",
              "[3372 rows x 89 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mu0BTcfP3kvb"
      },
      "source": [
        "import math\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJFysSJC3zVy"
      },
      "source": [
        "def create_dataset(dataset, look_back=1):\n",
        "\tdataX, dataY = [], []\n",
        "\tfor i in range(len(dataset)-look_back-1):\n",
        "\t\ta = dataset[i:(i+look_back), 0]\n",
        "\t\tdataX.append(a)\n",
        "\t\tdataY.append(dataset[i + look_back, 0])\n",
        "\treturn numpy.array(dataX), numpy.array(dataY)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXSD_mdV3_tV"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYD5Cotw4JcV"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(scaled_df.drop('SumOfHIV_infected' , axis = 1), scaled_df['SumOfHIV_infected'], test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bipEjgua5m_u"
      },
      "source": [
        "import numpy "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dc8GGRPw5_9M"
      },
      "source": [
        "X_train = X_train.values.reshape(2697 , 1 , 88)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CVYtIUr6MMg"
      },
      "source": [
        "X_test = X_test.values.reshape(675 , 1 , 88)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y38iQaYO9V7b"
      },
      "source": [
        "from tensorflow.keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XW-bvGWJ6Xet"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(4, input_shape=(1, 88)))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5T8L54k6ln_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a156dd9b-91b2-4441-e771-c61f202e12b2"
      },
      "source": [
        "model.fit(X_train , y_train , epochs = 50 , verbose = 2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "85/85 - 0s - loss: 0.0166\n",
            "Epoch 2/50\n",
            "85/85 - 0s - loss: 0.0112\n",
            "Epoch 3/50\n",
            "85/85 - 0s - loss: 0.0079\n",
            "Epoch 4/50\n",
            "85/85 - 0s - loss: 0.0055\n",
            "Epoch 5/50\n",
            "85/85 - 0s - loss: 0.0041\n",
            "Epoch 6/50\n",
            "85/85 - 0s - loss: 0.0035\n",
            "Epoch 7/50\n",
            "85/85 - 0s - loss: 0.0032\n",
            "Epoch 8/50\n",
            "85/85 - 0s - loss: 0.0031\n",
            "Epoch 9/50\n",
            "85/85 - 0s - loss: 0.0029\n",
            "Epoch 10/50\n",
            "85/85 - 0s - loss: 0.0029\n",
            "Epoch 11/50\n",
            "85/85 - 0s - loss: 0.0028\n",
            "Epoch 12/50\n",
            "85/85 - 0s - loss: 0.0028\n",
            "Epoch 13/50\n",
            "85/85 - 0s - loss: 0.0027\n",
            "Epoch 14/50\n",
            "85/85 - 0s - loss: 0.0027\n",
            "Epoch 15/50\n",
            "85/85 - 0s - loss: 0.0027\n",
            "Epoch 16/50\n",
            "85/85 - 0s - loss: 0.0026\n",
            "Epoch 17/50\n",
            "85/85 - 0s - loss: 0.0026\n",
            "Epoch 18/50\n",
            "85/85 - 0s - loss: 0.0026\n",
            "Epoch 19/50\n",
            "85/85 - 0s - loss: 0.0026\n",
            "Epoch 20/50\n",
            "85/85 - 0s - loss: 0.0026\n",
            "Epoch 21/50\n",
            "85/85 - 0s - loss: 0.0025\n",
            "Epoch 22/50\n",
            "85/85 - 0s - loss: 0.0025\n",
            "Epoch 23/50\n",
            "85/85 - 0s - loss: 0.0025\n",
            "Epoch 24/50\n",
            "85/85 - 0s - loss: 0.0025\n",
            "Epoch 25/50\n",
            "85/85 - 0s - loss: 0.0025\n",
            "Epoch 26/50\n",
            "85/85 - 0s - loss: 0.0024\n",
            "Epoch 27/50\n",
            "85/85 - 0s - loss: 0.0024\n",
            "Epoch 28/50\n",
            "85/85 - 0s - loss: 0.0024\n",
            "Epoch 29/50\n",
            "85/85 - 0s - loss: 0.0024\n",
            "Epoch 30/50\n",
            "85/85 - 0s - loss: 0.0024\n",
            "Epoch 31/50\n",
            "85/85 - 0s - loss: 0.0024\n",
            "Epoch 32/50\n",
            "85/85 - 0s - loss: 0.0023\n",
            "Epoch 33/50\n",
            "85/85 - 0s - loss: 0.0023\n",
            "Epoch 34/50\n",
            "85/85 - 0s - loss: 0.0023\n",
            "Epoch 35/50\n",
            "85/85 - 0s - loss: 0.0023\n",
            "Epoch 36/50\n",
            "85/85 - 0s - loss: 0.0023\n",
            "Epoch 37/50\n",
            "85/85 - 0s - loss: 0.0022\n",
            "Epoch 38/50\n",
            "85/85 - 0s - loss: 0.0022\n",
            "Epoch 39/50\n",
            "85/85 - 0s - loss: 0.0022\n",
            "Epoch 40/50\n",
            "85/85 - 0s - loss: 0.0022\n",
            "Epoch 41/50\n",
            "85/85 - 0s - loss: 0.0022\n",
            "Epoch 42/50\n",
            "85/85 - 0s - loss: 0.0022\n",
            "Epoch 43/50\n",
            "85/85 - 0s - loss: 0.0022\n",
            "Epoch 44/50\n",
            "85/85 - 0s - loss: 0.0022\n",
            "Epoch 45/50\n",
            "85/85 - 0s - loss: 0.0021\n",
            "Epoch 46/50\n",
            "85/85 - 0s - loss: 0.0021\n",
            "Epoch 47/50\n",
            "85/85 - 0s - loss: 0.0021\n",
            "Epoch 48/50\n",
            "85/85 - 0s - loss: 0.0021\n",
            "Epoch 49/50\n",
            "85/85 - 0s - loss: 0.0021\n",
            "Epoch 50/50\n",
            "85/85 - 0s - loss: 0.0021\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f37cd73a630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8VSpnu_6-dZ"
      },
      "source": [
        "pred = model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOXdGNsU8Yxp"
      },
      "source": [
        "from sklearn.metrics import r2_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GB_1vwFn8yDO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8b5cd32-de37-4a33-879e-8992d5f9d95c"
      },
      "source": [
        "r2_score(y_test , pred) #Vanilla LSTM"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9056936331346117"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMwGZEgf81hF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5d27e9b-e30a-480b-fe23-749ea32aa95b"
      },
      "source": [
        "r2_score(y_test , y_pred) #Bidirectional RNN"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8974135494608743"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0udOGIbNBTiW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5064fc6e-7369-4f10-edd3-a99552512ad3"
      },
      "source": [
        "r2_score(y_test , y_pred) #LSTM 1D"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8974135494608743"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjD3vheYBvHA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dbfc056-1184-4241-80df-18cd45e8d0b9"
      },
      "source": [
        "r2_score(y_test , y_pred) #LSTM 2D"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8974135494608743"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8i8geGDGRiK"
      },
      "source": [
        "from tensorflow.keras.layers import LSTM , Dropout , GRU , Bidirectional"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kau3DKdDE0zL"
      },
      "source": [
        "def create_model_bilstm(units):\n",
        "    model = Sequential()\n",
        "    model.add(Bidirectional(LSTM(units = units,                             \n",
        "              return_sequences=True),\n",
        "              input_shape=(1 , 88)))\n",
        "    model.add(Bidirectional(LSTM(units = units)))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(loss='mse', optimizer='adam')\n",
        "    return model\n",
        "\n",
        "def create_model(units, m):\n",
        "    model = Sequential()\n",
        "    model.add(m (units = units, return_sequences = True,\n",
        "                input_shape = (1 , 88)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(m (units = units))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(units = 1))\n",
        "    model.compile(loss='mse', optimizer='adam')\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEtSj-QdFv08"
      },
      "source": [
        "model_bilstm = create_model_bilstm(64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2alNTNbG33V"
      },
      "source": [
        "from tensorflow import keras\n",
        "early_stop = keras.callbacks.EarlyStopping(monitor = 'val_loss',patience = 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbxULihsGGpm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05c6c90c-3379-4b53-c25a-2ea585239800"
      },
      "source": [
        "model_bilstm.fit(X_train, y_train, epochs = 100, validation_split = 0.2, batch_size = 32, shuffle = False, callbacks = [early_stop])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "68/68 [==============================] - 2s 26ms/step - loss: 0.0093 - val_loss: 0.0024\n",
            "Epoch 2/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 0.0022 - val_loss: 0.0018\n",
            "Epoch 3/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 0.0020 - val_loss: 0.0018\n",
            "Epoch 4/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 0.0019 - val_loss: 0.0017\n",
            "Epoch 5/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 0.0019 - val_loss: 0.0017\n",
            "Epoch 6/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 7/100\n",
            "68/68 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.0017\n",
            "Epoch 8/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 0.0017\n",
            "Epoch 9/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 0.0016\n",
            "Epoch 10/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0016\n",
            "Epoch 11/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0016\n",
            "Epoch 12/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0016\n",
            "Epoch 13/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0016\n",
            "Epoch 14/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0016\n",
            "Epoch 15/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0015\n",
            "Epoch 16/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0015\n",
            "Epoch 17/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0015\n",
            "Epoch 18/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0015\n",
            "Epoch 19/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0014\n",
            "Epoch 20/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0014\n",
            "Epoch 21/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0014\n",
            "Epoch 22/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0014\n",
            "Epoch 23/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0014\n",
            "Epoch 24/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0013\n",
            "Epoch 25/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0013\n",
            "Epoch 26/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0013\n",
            "Epoch 27/100\n",
            "68/68 [==============================] - 0s 7ms/step - loss: 0.0011 - val_loss: 0.0013\n",
            "Epoch 28/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0013\n",
            "Epoch 29/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0012\n",
            "Epoch 30/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0012\n",
            "Epoch 31/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0012\n",
            "Epoch 32/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0012\n",
            "Epoch 33/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 0.0012\n",
            "Epoch 34/100\n",
            "68/68 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 0.0012\n",
            "Epoch 35/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0012\n",
            "Epoch 36/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0011\n",
            "Epoch 37/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 0.0010 - val_loss: 0.0011\n",
            "Epoch 38/100\n",
            "68/68 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 0.0011\n",
            "Epoch 39/100\n",
            "68/68 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 0.0011\n",
            "Epoch 40/100\n",
            "68/68 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 0.0011\n",
            "Epoch 41/100\n",
            "68/68 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 0.0011\n",
            "Epoch 42/100\n",
            "68/68 [==============================] - 0s 7ms/step - loss: 0.0010 - val_loss: 0.0011\n",
            "Epoch 43/100\n",
            "68/68 [==============================] - 0s 7ms/step - loss: 9.9644e-04 - val_loss: 0.0011\n",
            "Epoch 44/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 9.9213e-04 - val_loss: 0.0011\n",
            "Epoch 45/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 9.8802e-04 - val_loss: 0.0011\n",
            "Epoch 46/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 9.8411e-04 - val_loss: 0.0011\n",
            "Epoch 47/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 9.8038e-04 - val_loss: 0.0010\n",
            "Epoch 48/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 9.7683e-04 - val_loss: 0.0010\n",
            "Epoch 49/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 9.7345e-04 - val_loss: 0.0010\n",
            "Epoch 50/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 9.7022e-04 - val_loss: 0.0010\n",
            "Epoch 51/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 9.6714e-04 - val_loss: 0.0010\n",
            "Epoch 52/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 9.6419e-04 - val_loss: 0.0010\n",
            "Epoch 53/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 9.6136e-04 - val_loss: 0.0010\n",
            "Epoch 54/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 9.5864e-04 - val_loss: 9.9337e-04\n",
            "Epoch 55/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 9.5601e-04 - val_loss: 9.8692e-04\n",
            "Epoch 56/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 9.5344e-04 - val_loss: 9.8070e-04\n",
            "Epoch 57/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 9.5090e-04 - val_loss: 9.7474e-04\n",
            "Epoch 58/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 9.4836e-04 - val_loss: 9.6908e-04\n",
            "Epoch 59/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 9.4578e-04 - val_loss: 9.6378e-04\n",
            "Epoch 60/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 9.4313e-04 - val_loss: 9.5889e-04\n",
            "Epoch 61/100\n",
            "68/68 [==============================] - 0s 7ms/step - loss: 9.4034e-04 - val_loss: 9.5446e-04\n",
            "Epoch 62/100\n",
            "68/68 [==============================] - 0s 7ms/step - loss: 9.3737e-04 - val_loss: 9.5049e-04\n",
            "Epoch 63/100\n",
            "68/68 [==============================] - 0s 7ms/step - loss: 9.3419e-04 - val_loss: 9.4697e-04\n",
            "Epoch 64/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 9.3077e-04 - val_loss: 9.4396e-04\n",
            "Epoch 65/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 9.2709e-04 - val_loss: 9.4117e-04\n",
            "Epoch 66/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 9.2325e-04 - val_loss: 9.3855e-04\n",
            "Epoch 67/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 9.1925e-04 - val_loss: 9.3629e-04\n",
            "Epoch 68/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 9.1498e-04 - val_loss: 9.3433e-04\n",
            "Epoch 69/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 9.1047e-04 - val_loss: 9.3257e-04\n",
            "Epoch 70/100\n",
            "68/68 [==============================] - 0s 7ms/step - loss: 9.0573e-04 - val_loss: 9.3094e-04\n",
            "Epoch 71/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 9.0084e-04 - val_loss: 9.2940e-04\n",
            "Epoch 72/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 8.9584e-04 - val_loss: 9.2798e-04\n",
            "Epoch 73/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 8.9074e-04 - val_loss: 9.2671e-04\n",
            "Epoch 74/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 8.8568e-04 - val_loss: 9.2540e-04\n",
            "Epoch 75/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 8.8063e-04 - val_loss: 9.2412e-04\n",
            "Epoch 76/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 8.7549e-04 - val_loss: 9.2283e-04\n",
            "Epoch 77/100\n",
            "68/68 [==============================] - 0s 7ms/step - loss: 8.7040e-04 - val_loss: 9.2156e-04\n",
            "Epoch 78/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 8.6529e-04 - val_loss: 9.2051e-04\n",
            "Epoch 79/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 8.6026e-04 - val_loss: 9.1960e-04\n",
            "Epoch 80/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 8.5518e-04 - val_loss: 9.1867e-04\n",
            "Epoch 81/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 8.5009e-04 - val_loss: 9.1753e-04\n",
            "Epoch 82/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 8.4517e-04 - val_loss: 9.1633e-04\n",
            "Epoch 83/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 8.4016e-04 - val_loss: 9.1542e-04\n",
            "Epoch 84/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 8.3520e-04 - val_loss: 9.1472e-04\n",
            "Epoch 85/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 8.3026e-04 - val_loss: 9.1404e-04\n",
            "Epoch 86/100\n",
            "68/68 [==============================] - 0s 7ms/step - loss: 8.2528e-04 - val_loss: 9.1321e-04\n",
            "Epoch 87/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 8.2037e-04 - val_loss: 9.1218e-04\n",
            "Epoch 88/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 8.1548e-04 - val_loss: 9.1115e-04\n",
            "Epoch 89/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 8.1052e-04 - val_loss: 9.1032e-04\n",
            "Epoch 90/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 8.0548e-04 - val_loss: 9.0976e-04\n",
            "Epoch 91/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 8.0048e-04 - val_loss: 9.0925e-04\n",
            "Epoch 92/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 7.9559e-04 - val_loss: 9.0853e-04\n",
            "Epoch 93/100\n",
            "68/68 [==============================] - 0s 7ms/step - loss: 7.9075e-04 - val_loss: 9.0755e-04\n",
            "Epoch 94/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 7.8585e-04 - val_loss: 9.0653e-04\n",
            "Epoch 95/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 7.8073e-04 - val_loss: 9.0582e-04\n",
            "Epoch 96/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 7.7543e-04 - val_loss: 9.0547e-04\n",
            "Epoch 97/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 7.7034e-04 - val_loss: 9.0503e-04\n",
            "Epoch 98/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 7.6553e-04 - val_loss: 9.0424e-04\n",
            "Epoch 99/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 7.6077e-04 - val_loss: 9.0329e-04\n",
            "Epoch 100/100\n",
            "68/68 [==============================] - 0s 7ms/step - loss: 7.5588e-04 - val_loss: 9.0244e-04\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f94463871d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LD_98sVUHPKL"
      },
      "source": [
        "pred = model_bilstm.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXfPGxLXHsI5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a22a08bb-24c8-4df6-8110-a9988e118da1"
      },
      "source": [
        "r2_score(y_test , pred) #BiLSTM"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9042291073163864"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecmXUxQSHvyn"
      },
      "source": [
        "model_gru = create_model(64, GRU)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehF6ZyeKIHyu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ee798ca-8dd5-4fdd-ef29-cafbea0a8257"
      },
      "source": [
        "model_gru.fit(X_train, y_train, epochs = 100, validation_split = 0.2, batch_size = 32, shuffle = False, callbacks = [early_stop])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "68/68 [==============================] - 1s 13ms/step - loss: 0.0092 - val_loss: 0.0027\n",
            "Epoch 2/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0019\n",
            "Epoch 3/100\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0031 - val_loss: 0.0018\n",
            "Epoch 4/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0029 - val_loss: 0.0018\n",
            "Epoch 5/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0028 - val_loss: 0.0018\n",
            "Epoch 6/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0028 - val_loss: 0.0018\n",
            "Epoch 7/100\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0027 - val_loss: 0.0017\n",
            "Epoch 8/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0025 - val_loss: 0.0017\n",
            "Epoch 9/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0024 - val_loss: 0.0017\n",
            "Epoch 10/100\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0023 - val_loss: 0.0016\n",
            "Epoch 11/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0023 - val_loss: 0.0016\n",
            "Epoch 12/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0022 - val_loss: 0.0016\n",
            "Epoch 13/100\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0023 - val_loss: 0.0016\n",
            "Epoch 14/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0022 - val_loss: 0.0016\n",
            "Epoch 15/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0021 - val_loss: 0.0016\n",
            "Epoch 16/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0023 - val_loss: 0.0016\n",
            "Epoch 17/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0022 - val_loss: 0.0016\n",
            "Epoch 18/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0022 - val_loss: 0.0016\n",
            "Epoch 19/100\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0020 - val_loss: 0.0016\n",
            "Epoch 20/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0021 - val_loss: 0.0016\n",
            "Epoch 21/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.0015\n",
            "Epoch 22/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0021 - val_loss: 0.0016\n",
            "Epoch 23/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.0017\n",
            "Epoch 24/100\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0021 - val_loss: 0.0017\n",
            "Epoch 25/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.0015\n",
            "Epoch 26/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.0015\n",
            "Epoch 27/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.0015\n",
            "Epoch 28/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.0015\n",
            "Epoch 29/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.0015\n",
            "Epoch 30/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0015\n",
            "Epoch 31/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0016\n",
            "Epoch 32/100\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0015\n",
            "Epoch 33/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0015\n",
            "Epoch 34/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0015\n",
            "Epoch 35/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0015\n",
            "Epoch 36/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0014\n",
            "Epoch 37/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0015\n",
            "Epoch 38/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0014\n",
            "Epoch 39/100\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0016 - val_loss: 0.0014\n",
            "Epoch 40/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0015\n",
            "Epoch 41/100\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0016 - val_loss: 0.0014\n",
            "Epoch 42/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0014\n",
            "Epoch 43/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0014\n",
            "Epoch 44/100\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0016 - val_loss: 0.0014\n",
            "Epoch 45/100\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 0.0014\n",
            "Epoch 46/100\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0016 - val_loss: 0.0013\n",
            "Epoch 47/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0013\n",
            "Epoch 48/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0013\n",
            "Epoch 49/100\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0013\n",
            "Epoch 50/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0013\n",
            "Epoch 51/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0013\n",
            "Epoch 52/100\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 0.0013\n",
            "Epoch 53/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0013\n",
            "Epoch 54/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0012\n",
            "Epoch 55/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0012\n",
            "Epoch 56/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0012\n",
            "Epoch 57/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0012\n",
            "Epoch 58/100\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 0.0012\n",
            "Epoch 59/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0012\n",
            "Epoch 60/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0012\n",
            "Epoch 61/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0012\n",
            "Epoch 62/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0012\n",
            "Epoch 63/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0012\n",
            "Epoch 64/100\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 0.0011\n",
            "Epoch 65/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0011\n",
            "Epoch 66/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0012\n",
            "Epoch 67/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0011\n",
            "Epoch 68/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0011\n",
            "Epoch 69/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0012\n",
            "Epoch 70/100\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 0.0011\n",
            "Epoch 71/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0011\n",
            "Epoch 72/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0011\n",
            "Epoch 73/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0011\n",
            "Epoch 74/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0011\n",
            "Epoch 75/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0011\n",
            "Epoch 76/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0011\n",
            "Epoch 77/100\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 0.0011\n",
            "Epoch 78/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0011\n",
            "Epoch 79/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0011\n",
            "Epoch 80/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0011\n",
            "Epoch 81/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0011\n",
            "Epoch 82/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0011\n",
            "Epoch 83/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0011\n",
            "Epoch 84/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0011\n",
            "Epoch 85/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0011\n",
            "Epoch 86/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0011\n",
            "Epoch 87/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0011\n",
            "Epoch 88/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0010\n",
            "Epoch 89/100\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 0.0010\n",
            "Epoch 90/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0012\n",
            "Epoch 91/100\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 0.0010\n",
            "Epoch 92/100\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 0.0010\n",
            "Epoch 93/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0010\n",
            "Epoch 94/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0011\n",
            "Epoch 95/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 9.9951e-04\n",
            "Epoch 96/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0010\n",
            "Epoch 97/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0010\n",
            "Epoch 98/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0010\n",
            "Epoch 99/100\n",
            "68/68 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 0.0011\n",
            "Epoch 100/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 0.0012 - val_loss: 0.0010\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f943b612da0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxeWDGcWITH0"
      },
      "source": [
        "pred = model_gru.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKatJAniIoaQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04985ee2-347d-426a-9d0f-6519d4486c59"
      },
      "source": [
        "r2_score(y_test , pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8964469769740756"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhr6vjVlItL0"
      },
      "source": [
        "model_lstm = create_model(64, LSTM)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWTGKUhDI0QM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42736ea4-1570-4d55-c0f6-732bd2929dc9"
      },
      "source": [
        "model_lstm.fit(X_train, y_train, epochs = 100, validation_split = 0.2, batch_size = 32, shuffle = False, callbacks = [early_stop])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "68/68 [==============================] - 1s 14ms/step - loss: 0.0140 - val_loss: 0.0051\n",
            "Epoch 2/100\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0020\n",
            "Epoch 3/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0024 - val_loss: 0.0019\n",
            "Epoch 4/100\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0025 - val_loss: 0.0018\n",
            "Epoch 5/100\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0023 - val_loss: 0.0017\n",
            "Epoch 6/100\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0017\n",
            "Epoch 7/100\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0023 - val_loss: 0.0017\n",
            "Epoch 8/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0022 - val_loss: 0.0017\n",
            "Epoch 9/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.0016\n",
            "Epoch 10/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0022 - val_loss: 0.0016\n",
            "Epoch 11/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.0016\n",
            "Epoch 12/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0021 - val_loss: 0.0016\n",
            "Epoch 13/100\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0021 - val_loss: 0.0016\n",
            "Epoch 14/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.0016\n",
            "Epoch 15/100\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0019 - val_loss: 0.0015\n",
            "Epoch 16/100\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0016\n",
            "Epoch 17/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0015\n",
            "Epoch 18/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0015\n",
            "Epoch 19/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.0015\n",
            "Epoch 20/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0015\n",
            "Epoch 21/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0015\n",
            "Epoch 22/100\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0016 - val_loss: 0.0015\n",
            "Epoch 23/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0015\n",
            "Epoch 24/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0014\n",
            "Epoch 25/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0014\n",
            "Epoch 26/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0017 - val_loss: 0.0014\n",
            "Epoch 27/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0014\n",
            "Epoch 28/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0014\n",
            "Epoch 29/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0014\n",
            "Epoch 30/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0013\n",
            "Epoch 31/100\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 0.0013\n",
            "Epoch 32/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0013\n",
            "Epoch 33/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0013\n",
            "Epoch 34/100\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0016 - val_loss: 0.0013\n",
            "Epoch 35/100\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0016 - val_loss: 0.0012\n",
            "Epoch 36/100\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 0.0012\n",
            "Epoch 37/100\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 0.0012\n",
            "Epoch 38/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0012\n",
            "Epoch 39/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0012\n",
            "Epoch 40/100\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 0.0012\n",
            "Epoch 41/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0012\n",
            "Epoch 42/100\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 0.0012\n",
            "Epoch 43/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0012\n",
            "Epoch 44/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0011\n",
            "Epoch 45/100\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 0.0012\n",
            "Epoch 46/100\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 0.0011\n",
            "Epoch 47/100\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 0.0012\n",
            "Epoch 48/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0011\n",
            "Epoch 49/100\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 0.0011\n",
            "Epoch 50/100\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 0.0011\n",
            "Epoch 51/100\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 0.0011\n",
            "Epoch 52/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0011\n",
            "Epoch 53/100\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 0.0011\n",
            "Epoch 54/100\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 0.0011\n",
            "Epoch 55/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0011\n",
            "Epoch 56/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0011\n",
            "Epoch 57/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0011\n",
            "Epoch 58/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0011\n",
            "Epoch 59/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0011\n",
            "Epoch 60/100\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 0.0011\n",
            "Epoch 61/100\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 0.0011\n",
            "Epoch 62/100\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 0.0011\n",
            "Epoch 63/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0010\n",
            "Epoch 64/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0011\n",
            "Epoch 65/100\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 0.0011\n",
            "Epoch 66/100\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 0.0011\n",
            "Epoch 67/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0010\n",
            "Epoch 68/100\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 0.0010\n",
            "Epoch 69/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0010\n",
            "Epoch 70/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0011\n",
            "Epoch 71/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0010\n",
            "Epoch 72/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0010\n",
            "Epoch 73/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0010\n",
            "Epoch 74/100\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 0.0011\n",
            "Epoch 75/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0010\n",
            "Epoch 76/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0010\n",
            "Epoch 77/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0010\n",
            "Epoch 78/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0010\n",
            "Epoch 79/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0010\n",
            "Epoch 80/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0010\n",
            "Epoch 81/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0010\n",
            "Epoch 82/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0010\n",
            "Epoch 83/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 0.0010\n",
            "Epoch 84/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0010\n",
            "Epoch 85/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0010\n",
            "Epoch 86/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0010\n",
            "Epoch 87/100\n",
            "68/68 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 9.9365e-04\n",
            "Epoch 88/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0010\n",
            "Epoch 89/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0010\n",
            "Epoch 90/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 9.8424e-04\n",
            "Epoch 91/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 9.9078e-04\n",
            "Epoch 92/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0012 - val_loss: 9.8933e-04\n",
            "Epoch 93/100\n",
            "68/68 [==============================] - 0s 5ms/step - loss: 0.0011 - val_loss: 0.0010\n",
            "Epoch 94/100\n",
            "68/68 [==============================] - 0s 6ms/step - loss: 0.0011 - val_loss: 9.7975e-04\n",
            "Epoch 95/100\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0012 - val_loss: 0.0010\n",
            "Epoch 96/100\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 9.8582e-04\n",
            "Epoch 97/100\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 0.0010\n",
            "Epoch 98/100\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 9.6879e-04\n",
            "Epoch 99/100\n",
            "68/68 [==============================] - 1s 9ms/step - loss: 0.0011 - val_loss: 9.7557e-04\n",
            "Epoch 100/100\n",
            "68/68 [==============================] - 1s 8ms/step - loss: 0.0011 - val_loss: 9.6771e-04\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f943aab3d68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXRM4eRPI8fA"
      },
      "source": [
        "pred = model_lstm.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSTmh_WOJMaf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cba5e1a6-ca2a-48b2-fbdc-e19473f91739"
      },
      "source": [
        "r2_score(y_test , pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9003415647368461"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7x3bVdWJQ1U"
      },
      "source": [
        "#PEDIATRIC"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbzrEea-O88m"
      },
      "source": [
        "pred = model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbQep8xYO9uW"
      },
      "source": [
        "from sklearn.metrics import r2_score , mean_absolute_error , mean_squared_error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUrnRmVyPEDD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8e5551c-f9f5-43dc-f155-dcd22c89f46e"
      },
      "source": [
        "r2_score(y_test , pred) #Pediatric Test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8272581422818612"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HiSdTIJsPSjF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59136d63-a686-4388-c726-bb16208c8846"
      },
      "source": [
        "mean_absolute_error(y_test , pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.03413500066861024"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToKy8rQyPYsz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9eba80c5-b46d-4b17-ce41-05404d36e27a"
      },
      "source": [
        "mean_squared_error(y_test , pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.002380809598005426"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6TCYxyYPcb2"
      },
      "source": [
        "#TRAIN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fta0SFfKPfWT"
      },
      "source": [
        "Y_TRAIN_PRED = model.predict(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yQbHN4oPkNg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7693734b-16f0-4c53-8ef3-28b2147b6dd2"
      },
      "source": [
        "r2_score(y_train , Y_TRAIN_PRED)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8663057849377733"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0FUvDd1PtzK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "395f5d6e-c72c-4a42-cbd8-ccc2086d7feb"
      },
      "source": [
        "mean_absolute_error(y_train , Y_TRAIN_PRED)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.03230865854419453"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DE0cQwfKPyVO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f65e236-bfad-4197-e591-4930c0fb240c"
      },
      "source": [
        "mean_squared_error(y_train , Y_TRAIN_PRED)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.002249948944071933"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iyj_pQIP0PR"
      },
      "source": [
        "#GERIATRIC"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKXd_PLyP1_W"
      },
      "source": [
        "pred = model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s78ryOqcTQU4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ca69f46-e072-4673-de94-1b8f79c6fda8"
      },
      "source": [
        "r2_score(y_test , pred) #Geriatric Test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8700303759525237"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dO7I1KHLTVQq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6c4db73-de6b-4d1a-afa9-609706c32c99"
      },
      "source": [
        "mean_absolute_error(y_test , pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.03396449560656157"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5HGrICJTnEY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d2f6b62-ed99-45f2-ae6b-f99a6822ae14"
      },
      "source": [
        "mean_squared_error(y_test , pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0018805327749751438"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5xVelGUTppr"
      },
      "source": [
        "#Train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpr2vu3oTrCD"
      },
      "source": [
        "Y_TRAIN_PRED = model.predict(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRAf7EC3Ts3Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4a88e6d-a4f9-45a9-fb63-8ef86d625f89"
      },
      "source": [
        "r2_score(y_train , Y_TRAIN_PRED)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9011697369207206"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qR3v-BRgT2zB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a704dba0-563b-4f65-99d2-71ca133d5de0"
      },
      "source": [
        "mean_absolute_error(y_train , Y_TRAIN_PRED)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.029813304129812614"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvgzP3OmT5-p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84aaaa88-0215-4040-fa68-3aa66e411d2f"
      },
      "source": [
        "mean_squared_error(y_train , Y_TRAIN_PRED)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0015773987181507863"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjxE1UwYT952"
      },
      "source": [
        "# HIV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7OygtItUHIx"
      },
      "source": [
        "pred = model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbXf7ZyaUgke",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35f97ff7-343b-45ea-ccbb-3bbfd6fb4369"
      },
      "source": [
        "r2_score(y_test , pred) #HIV Test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8349750055331905"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTJh4MZ2Ujet",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41f1c01f-501d-4899-e22c-5b2b9298f6fa"
      },
      "source": [
        "mean_absolute_error(y_test , pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.025265051817021725"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqyiLv6xUl7N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4231a62-d36f-45d3-d243-d5a210043f00"
      },
      "source": [
        "mean_squared_error(y_test , pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.001867124927066518"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Df_TrphoUnxU"
      },
      "source": [
        "#TRAIN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5CqiJksUqsi"
      },
      "source": [
        "Y_TRAIN_PRED = model.predict(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tb_JRAoGUs-H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df764ff5-862f-4e80-8131-7f75879d57c6"
      },
      "source": [
        "r2_score(y_train , Y_TRAIN_PRED)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8537044115912104"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kv-IldsgUvTG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c8c17c0-91fe-4902-996e-9e8f0811c27a"
      },
      "source": [
        "mean_absolute_error(y_train , Y_TRAIN_PRED)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.024875931270304057"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBHEZAnfUxbD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1583b3d9-6d53-4561-b9a0-9228949e051d"
      },
      "source": [
        "mean_squared_error(y_train , Y_TRAIN_PRED)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.002063532698167419"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfOeOCx8U1gx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}