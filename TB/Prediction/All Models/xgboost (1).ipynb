{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "xgboost.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCxCJ1cZRBSB"
      },
      "source": [
        "from xgboost import XGBRegressor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ac9X1FMeRC5V"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTFsk2hlRfA-"
      },
      "source": [
        "test = pd.read_csv(\"Final_Test1.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaslDGqpRpDZ"
      },
      "source": [
        "train = pd.read_csv(\"finaltrain1.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zveoHtQRs9A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "64ddf763-af58-44d4-cbe8-443b7b96740d"
      },
      "source": [
        "test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1484, 75)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdSNO5a1RuSO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c8bfc7c4-94c2-42fa-aa90-a13bc88f2c24"
      },
      "source": [
        "train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2332, 76)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_kAFpWFRvug",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "outputId": "a93c14b2-a72d-4da0-a3bd-520c59f5e1f9"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Assam</th>\n",
              "      <th>Kerala</th>\n",
              "      <th>Punjab</th>\n",
              "      <th>ALAPPUZHA</th>\n",
              "      <th>AMRITSAR</th>\n",
              "      <th>BARNALA</th>\n",
              "      <th>BARPETA</th>\n",
              "      <th>BATHINDA</th>\n",
              "      <th>BONGAIGAON</th>\n",
              "      <th>CACHAR</th>\n",
              "      <th>DARRANG</th>\n",
              "      <th>DHEMAJI</th>\n",
              "      <th>DHUBRI</th>\n",
              "      <th>DIBRUGARH</th>\n",
              "      <th>ERNAKULAM</th>\n",
              "      <th>FARIDKOT</th>\n",
              "      <th>FIROZPUR</th>\n",
              "      <th>GOALPARA</th>\n",
              "      <th>GOLAGHAT</th>\n",
              "      <th>GURDASPUR</th>\n",
              "      <th>HAILAKANDI</th>\n",
              "      <th>HOSHIARPUR</th>\n",
              "      <th>IDUKKI</th>\n",
              "      <th>JALANDHAR</th>\n",
              "      <th>JORHAT</th>\n",
              "      <th>KAMRUP</th>\n",
              "      <th>KANNUR</th>\n",
              "      <th>KAPURTHALA</th>\n",
              "      <th>KARBI_ANGLONG</th>\n",
              "      <th>KARIMGANJ</th>\n",
              "      <th>KASARAGOD</th>\n",
              "      <th>KOKRAJHAR</th>\n",
              "      <th>KOLLAM</th>\n",
              "      <th>KOTTAYAM</th>\n",
              "      <th>KOZHIKODE</th>\n",
              "      <th>LUDHIANA</th>\n",
              "      <th>MALAPPURAM</th>\n",
              "      <th>MANSA</th>\n",
              "      <th>MARIGAON</th>\n",
              "      <th>MOGA</th>\n",
              "      <th>MUKTSAR</th>\n",
              "      <th>NAGAON</th>\n",
              "      <th>NALBARI</th>\n",
              "      <th>NAWANSHAHR</th>\n",
              "      <th>NORTH_CACHAR_HILLS</th>\n",
              "      <th>PALAKKAD</th>\n",
              "      <th>PATHANAMTHITTA</th>\n",
              "      <th>PATIALA</th>\n",
              "      <th>RUPNAGAR</th>\n",
              "      <th>SANGRUR</th>\n",
              "      <th>SIBSAGAR</th>\n",
              "      <th>SONITPUR</th>\n",
              "      <th>THIRUVANANTHAPURAM</th>\n",
              "      <th>THRISSUR</th>\n",
              "      <th>TINSUKIA</th>\n",
              "      <th>WAYANAD</th>\n",
              "      <th>QTR</th>\n",
              "      <th>YR</th>\n",
              "      <th>NSP Total/ NewMicConf Total</th>\n",
              "      <th>NEP Male</th>\n",
              "      <th>NEP Female</th>\n",
              "      <th>0-14 yrs NSP(NewAll207+) Male</th>\n",
              "      <th>0-14 yrs NSP(NewAll207+) Female</th>\n",
              "      <th>15-24 yrs NSP(NewAll207+) Male</th>\n",
              "      <th>15-24 yrs NSP(NewAll207+) Female</th>\n",
              "      <th>25-34 yrs NSP(NewAll207+) Male</th>\n",
              "      <th>25-34 yrs NSP(NewAll207+) Female</th>\n",
              "      <th>35-44 yrs NSP(NewAll207+) Male</th>\n",
              "      <th>35-44 yrs NSP(NewAll207+) Female</th>\n",
              "      <th>45-54 yrs NSP(NewAll207+) Male</th>\n",
              "      <th>45-54 yrs NSP(NewAll207+) Female</th>\n",
              "      <th>65 &amp; above yrs NSP(NewAll207+) Male</th>\n",
              "      <th>65 &amp; above yrs NSP(NewAll207+) Female</th>\n",
              "      <th>Total Failure</th>\n",
              "      <th>SumOfHIV_Tested</th>\n",
              "      <th>SumOfHIV_infected</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2008</td>\n",
              "      <td>184</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>26</td>\n",
              "      <td>12</td>\n",
              "      <td>29</td>\n",
              "      <td>17</td>\n",
              "      <td>24</td>\n",
              "      <td>10</td>\n",
              "      <td>19</td>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2008</td>\n",
              "      <td>216</td>\n",
              "      <td>36</td>\n",
              "      <td>25</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>26</td>\n",
              "      <td>5</td>\n",
              "      <td>32</td>\n",
              "      <td>16</td>\n",
              "      <td>32</td>\n",
              "      <td>10</td>\n",
              "      <td>30</td>\n",
              "      <td>5</td>\n",
              "      <td>24</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2008</td>\n",
              "      <td>172</td>\n",
              "      <td>32</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>22</td>\n",
              "      <td>12</td>\n",
              "      <td>33</td>\n",
              "      <td>9</td>\n",
              "      <td>20</td>\n",
              "      <td>10</td>\n",
              "      <td>28</td>\n",
              "      <td>2</td>\n",
              "      <td>16</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2008</td>\n",
              "      <td>172</td>\n",
              "      <td>19</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>29</td>\n",
              "      <td>13</td>\n",
              "      <td>29</td>\n",
              "      <td>8</td>\n",
              "      <td>30</td>\n",
              "      <td>7</td>\n",
              "      <td>22</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2009</td>\n",
              "      <td>184</td>\n",
              "      <td>27</td>\n",
              "      <td>22</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>13</td>\n",
              "      <td>28</td>\n",
              "      <td>11</td>\n",
              "      <td>26</td>\n",
              "      <td>5</td>\n",
              "      <td>23</td>\n",
              "      <td>7</td>\n",
              "      <td>23</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Assam  Kerala  Punjab  ...  Total Failure  SumOfHIV_Tested  SumOfHIV_infected\n",
              "0      1       0       0  ...              2                0                  0\n",
              "1      1       0       0  ...              9                0                  0\n",
              "2      1       0       0  ...              8                0                  0\n",
              "3      1       0       0  ...              8                0                  0\n",
              "4      1       0       0  ...              5               20                  0\n",
              "\n",
              "[5 rows x 76 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzAz_GzmRxri"
      },
      "source": [
        "X = train.drop(\"NSP Total/ NewMicConf Total\" , axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9japQLbER-N_"
      },
      "source": [
        "y = train['NSP Total/ NewMicConf Total']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhOqnaPeSAfI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c8313d28-e21a-461c-d973-3af5d27aa977"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2332, 75)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZTBQfnVSB_6"
      },
      "source": [
        "model = XGBRegressor()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaUIuysfSH94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "84d16bdb-5520-49de-d049-d4efb88fc448"
      },
      "source": [
        "model.fit(X , y , eval_metric = 'rmse')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[11:09:36] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "             colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "             importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
              "             max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
              "             n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
              "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "             silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6u5VKijsTDu8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "0a40512e-8dfe-4b5c-cc06-b9cc89153e91"
      },
      "source": [
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "             colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
            "             importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
            "             max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
            "             n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
            "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
            "             silent=None, subsample=1, verbosity=1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgmPz6biTPP2"
      },
      "source": [
        "pred = model.predict(test2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYSekwtcTcHE"
      },
      "source": [
        "test2 =  test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GTq3F_sTjV6"
      },
      "source": [
        "tcolumn = X.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LB6wiHxCTn5a"
      },
      "source": [
        "test2.columns = tcolumn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFJ2nAybTrvD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f50d854a-2f72-40b5-b296-ba1c5be75f73"
      },
      "source": [
        "print(pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[118.95247 150.7717  128.83354 ... 306.4668  288.5915  242.87758]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dx9H948uTzrH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "outputId": "1ad9c2c9-8be6-4c7c-b999-95ca1829affd"
      },
      "source": [
        "test2.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Assam</th>\n",
              "      <th>Kerala</th>\n",
              "      <th>Punjab</th>\n",
              "      <th>ALAPPUZHA</th>\n",
              "      <th>AMRITSAR</th>\n",
              "      <th>BARNALA</th>\n",
              "      <th>BARPETA</th>\n",
              "      <th>BATHINDA</th>\n",
              "      <th>BONGAIGAON</th>\n",
              "      <th>CACHAR</th>\n",
              "      <th>DARRANG</th>\n",
              "      <th>DHEMAJI</th>\n",
              "      <th>DHUBRI</th>\n",
              "      <th>DIBRUGARH</th>\n",
              "      <th>ERNAKULAM</th>\n",
              "      <th>FARIDKOT</th>\n",
              "      <th>FIROZPUR</th>\n",
              "      <th>GOALPARA</th>\n",
              "      <th>GOLAGHAT</th>\n",
              "      <th>GURDASPUR</th>\n",
              "      <th>HAILAKANDI</th>\n",
              "      <th>HOSHIARPUR</th>\n",
              "      <th>IDUKKI</th>\n",
              "      <th>JALANDHAR</th>\n",
              "      <th>JORHAT</th>\n",
              "      <th>KAMRUP</th>\n",
              "      <th>KANNUR</th>\n",
              "      <th>KAPURTHALA</th>\n",
              "      <th>KARBI_ANGLONG</th>\n",
              "      <th>KARIMGANJ</th>\n",
              "      <th>KASARAGOD</th>\n",
              "      <th>KOKRAJHAR</th>\n",
              "      <th>KOLLAM</th>\n",
              "      <th>KOTTAYAM</th>\n",
              "      <th>KOZHIKODE</th>\n",
              "      <th>LUDHIANA</th>\n",
              "      <th>MALAPPURAM</th>\n",
              "      <th>MANSA</th>\n",
              "      <th>MARIGAON</th>\n",
              "      <th>MOGA</th>\n",
              "      <th>MUKTSAR</th>\n",
              "      <th>NAGAON</th>\n",
              "      <th>NALBARI</th>\n",
              "      <th>NAWANSHAHR</th>\n",
              "      <th>NORTH_CACHAR_HILLS</th>\n",
              "      <th>PALAKKAD</th>\n",
              "      <th>PATHANAMTHITTA</th>\n",
              "      <th>PATIALA</th>\n",
              "      <th>RUPNAGAR</th>\n",
              "      <th>SANGRUR</th>\n",
              "      <th>SIBSAGAR</th>\n",
              "      <th>SONITPUR</th>\n",
              "      <th>THIRUVANANTHAPURAM</th>\n",
              "      <th>THRISSUR</th>\n",
              "      <th>TINSUKIA</th>\n",
              "      <th>WAYANAD</th>\n",
              "      <th>QTR</th>\n",
              "      <th>YR</th>\n",
              "      <th>NEP Male</th>\n",
              "      <th>NEP Female</th>\n",
              "      <th>0-14 yrs NSP(NewAll207+) Male</th>\n",
              "      <th>0-14 yrs NSP(NewAll207+) Female</th>\n",
              "      <th>15-24 yrs NSP(NewAll207+) Male</th>\n",
              "      <th>15-24 yrs NSP(NewAll207+) Female</th>\n",
              "      <th>25-34 yrs NSP(NewAll207+) Male</th>\n",
              "      <th>25-34 yrs NSP(NewAll207+) Female</th>\n",
              "      <th>35-44 yrs NSP(NewAll207+) Male</th>\n",
              "      <th>35-44 yrs NSP(NewAll207+) Female</th>\n",
              "      <th>45-54 yrs NSP(NewAll207+) Male</th>\n",
              "      <th>45-54 yrs NSP(NewAll207+) Female</th>\n",
              "      <th>65 &amp; above yrs NSP(NewAll207+) Male</th>\n",
              "      <th>65 &amp; above yrs NSP(NewAll207+) Female</th>\n",
              "      <th>Total Failure</th>\n",
              "      <th>SumOfHIV_Tested</th>\n",
              "      <th>SumOfHIV_infected</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2019</td>\n",
              "      <td>28.823180</td>\n",
              "      <td>11.715977</td>\n",
              "      <td>1.177222</td>\n",
              "      <td>-0.016659</td>\n",
              "      <td>18.075305</td>\n",
              "      <td>4.843709</td>\n",
              "      <td>13.722017</td>\n",
              "      <td>13.722017</td>\n",
              "      <td>17.247100</td>\n",
              "      <td>6.050692</td>\n",
              "      <td>14.710735</td>\n",
              "      <td>4.012241</td>\n",
              "      <td>8.691033</td>\n",
              "      <td>3.327240</td>\n",
              "      <td>-0.227780</td>\n",
              "      <td>34.026407</td>\n",
              "      <td>1.179621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2019</td>\n",
              "      <td>30.365321</td>\n",
              "      <td>13.627000</td>\n",
              "      <td>1.663287</td>\n",
              "      <td>0.828787</td>\n",
              "      <td>20.561474</td>\n",
              "      <td>9.605000</td>\n",
              "      <td>18.584034</td>\n",
              "      <td>18.584034</td>\n",
              "      <td>19.369328</td>\n",
              "      <td>4.458194</td>\n",
              "      <td>20.337412</td>\n",
              "      <td>7.132939</td>\n",
              "      <td>15.424478</td>\n",
              "      <td>3.432975</td>\n",
              "      <td>1.296115</td>\n",
              "      <td>28.624761</td>\n",
              "      <td>0.653545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2019</td>\n",
              "      <td>33.964463</td>\n",
              "      <td>10.900487</td>\n",
              "      <td>1.047890</td>\n",
              "      <td>1.516932</td>\n",
              "      <td>14.334737</td>\n",
              "      <td>5.889531</td>\n",
              "      <td>15.220087</td>\n",
              "      <td>15.220087</td>\n",
              "      <td>16.478766</td>\n",
              "      <td>4.899997</td>\n",
              "      <td>18.300368</td>\n",
              "      <td>5.968522</td>\n",
              "      <td>15.400414</td>\n",
              "      <td>2.341684</td>\n",
              "      <td>-0.350036</td>\n",
              "      <td>3.080554</td>\n",
              "      <td>0.896376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2019</td>\n",
              "      <td>34.852782</td>\n",
              "      <td>11.316671</td>\n",
              "      <td>0.625407</td>\n",
              "      <td>1.312828</td>\n",
              "      <td>12.942151</td>\n",
              "      <td>4.875121</td>\n",
              "      <td>13.304614</td>\n",
              "      <td>13.304614</td>\n",
              "      <td>11.671526</td>\n",
              "      <td>4.010644</td>\n",
              "      <td>20.245282</td>\n",
              "      <td>2.987618</td>\n",
              "      <td>11.668316</td>\n",
              "      <td>2.129942</td>\n",
              "      <td>-0.572127</td>\n",
              "      <td>23.321421</td>\n",
              "      <td>0.601024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2020</td>\n",
              "      <td>33.102027</td>\n",
              "      <td>14.837473</td>\n",
              "      <td>1.911002</td>\n",
              "      <td>0.955744</td>\n",
              "      <td>20.629092</td>\n",
              "      <td>6.948342</td>\n",
              "      <td>15.299481</td>\n",
              "      <td>15.299481</td>\n",
              "      <td>20.165892</td>\n",
              "      <td>6.157273</td>\n",
              "      <td>20.988359</td>\n",
              "      <td>4.455603</td>\n",
              "      <td>12.292225</td>\n",
              "      <td>3.511142</td>\n",
              "      <td>0.405213</td>\n",
              "      <td>20.879100</td>\n",
              "      <td>0.927936</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Assam  Kerala  Punjab  ...  Total Failure  SumOfHIV_Tested  SumOfHIV_infected\n",
              "0      1       0       0  ...      -0.227780        34.026407           1.179621\n",
              "1      1       0       0  ...       1.296115        28.624761           0.653545\n",
              "2      1       0       0  ...      -0.350036         3.080554           0.896376\n",
              "3      1       0       0  ...      -0.572127        23.321421           0.601024\n",
              "4      1       0       0  ...       0.405213        20.879100           0.927936\n",
              "\n",
              "[5 rows x 75 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_skOquMAT4bZ"
      },
      "source": [
        "pp = pd.read_csv(\"PredictionDataFrame.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDcTfwh1WS-l"
      },
      "source": [
        "XGBoost_Output = pd.concat([pp , prediction] , axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mx1cNQelWUcA"
      },
      "source": [
        "prediction = pd.DataFrame(pred , columns = [\"Total No of TB Cases\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvplgNCXWnb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "2ffc19d1-fce6-4775-b85d-3059d86bfae4"
      },
      "source": [
        "prediction.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Total No of TB Cases</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>118.952469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>150.771698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>128.833542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>113.715942</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>148.217834</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Total No of TB Cases\n",
              "0            118.952469\n",
              "1            150.771698\n",
              "2            128.833542\n",
              "3            113.715942\n",
              "4            148.217834"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYb3ICU2WxKC"
      },
      "source": [
        "XGBoost_Output.to_csv(\"XGBoost_Output.csv\" , index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rhn1gHexXH6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "a600943f-e80b-47a1-8082-cfb5f520dd72"
      },
      "source": [
        "from google.colab import files\n",
        "files.download(\"XGBoost_Output.csv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_4fb4e251-c189-4f6c-968c-3d2f3db937c0\", \"XGBoost_Output.csv\", 48537)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gU3olffkX2fF"
      },
      "source": [
        "from keras.layers import Dropout\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvufPj5qYm9K"
      },
      "source": [
        "from keras.layers import Dense\n",
        "from keras.models import Sequential"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApGjHwXWYyeT"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dropout(0.2, input_shape=(75,)))\n",
        "model.add(Dense(500,  activation= \"relu\"))\n",
        "model.add(Dense(100, activation= \"relu\"))\n",
        "model.add(Dense(50, activation= \"relu\"))\n",
        "model.add(Dense(1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyuGwVKwZqyT"
      },
      "source": [
        "model.compile(loss= \"mean_squared_error\" , optimizer=\"adam\", metrics=[\"mean_squared_error\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xm8Xt8uXZ32U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c0d5d7cc-fd4a-46ca-9995-c9606d113f22"
      },
      "source": [
        "model.fit(X , y , epochs=250)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 6635.8428 - mean_squared_error: 6635.8428\n",
            "Epoch 2/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 1583.2681 - mean_squared_error: 1583.2681\n",
            "Epoch 3/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 1483.3179 - mean_squared_error: 1483.3179\n",
            "Epoch 4/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 1318.7748 - mean_squared_error: 1318.7748\n",
            "Epoch 5/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 1395.9967 - mean_squared_error: 1395.9967\n",
            "Epoch 6/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 1296.5353 - mean_squared_error: 1296.5353\n",
            "Epoch 7/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 1284.3923 - mean_squared_error: 1284.3923\n",
            "Epoch 8/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 1400.6825 - mean_squared_error: 1400.6825\n",
            "Epoch 9/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 1277.3268 - mean_squared_error: 1277.3268\n",
            "Epoch 10/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 1268.0770 - mean_squared_error: 1268.0770\n",
            "Epoch 11/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 1128.1072 - mean_squared_error: 1128.1072\n",
            "Epoch 12/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 1055.2087 - mean_squared_error: 1055.2087\n",
            "Epoch 13/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 1248.8635 - mean_squared_error: 1248.8635\n",
            "Epoch 14/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 886.0955 - mean_squared_error: 886.0955\n",
            "Epoch 15/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 1062.6061 - mean_squared_error: 1062.6061\n",
            "Epoch 16/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 1198.3429 - mean_squared_error: 1198.3429\n",
            "Epoch 17/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 1088.1353 - mean_squared_error: 1088.1353\n",
            "Epoch 18/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 1016.2656 - mean_squared_error: 1016.2656\n",
            "Epoch 19/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 931.1268 - mean_squared_error: 931.1268\n",
            "Epoch 20/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 1083.0017 - mean_squared_error: 1083.0017\n",
            "Epoch 21/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 903.1096 - mean_squared_error: 903.1096\n",
            "Epoch 22/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 928.3804 - mean_squared_error: 928.3804\n",
            "Epoch 23/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 1093.8822 - mean_squared_error: 1093.8822\n",
            "Epoch 24/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 980.2619 - mean_squared_error: 980.2619\n",
            "Epoch 25/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 928.5427 - mean_squared_error: 928.5427\n",
            "Epoch 26/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 914.0588 - mean_squared_error: 914.0588\n",
            "Epoch 27/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 1028.7509 - mean_squared_error: 1028.7509\n",
            "Epoch 28/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 885.1851 - mean_squared_error: 885.1851\n",
            "Epoch 29/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 950.4613 - mean_squared_error: 950.4613\n",
            "Epoch 30/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 745.3082 - mean_squared_error: 745.3082\n",
            "Epoch 31/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 744.6714 - mean_squared_error: 744.6714\n",
            "Epoch 32/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 754.8997 - mean_squared_error: 754.8997\n",
            "Epoch 33/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 844.3642 - mean_squared_error: 844.3642\n",
            "Epoch 34/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 682.5306 - mean_squared_error: 682.5306\n",
            "Epoch 35/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 748.2615 - mean_squared_error: 748.2615\n",
            "Epoch 36/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 702.0458 - mean_squared_error: 702.0458\n",
            "Epoch 37/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 682.9371 - mean_squared_error: 682.9371\n",
            "Epoch 38/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 671.6254 - mean_squared_error: 671.6254\n",
            "Epoch 39/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 708.5165 - mean_squared_error: 708.5165\n",
            "Epoch 40/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 673.3392 - mean_squared_error: 673.3392\n",
            "Epoch 41/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 650.4283 - mean_squared_error: 650.4283\n",
            "Epoch 42/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 651.5997 - mean_squared_error: 651.5997\n",
            "Epoch 43/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 537.0997 - mean_squared_error: 537.0997\n",
            "Epoch 44/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 554.8475 - mean_squared_error: 554.8475\n",
            "Epoch 45/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 587.1644 - mean_squared_error: 587.1644\n",
            "Epoch 46/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 687.2860 - mean_squared_error: 687.2860\n",
            "Epoch 47/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 594.4967 - mean_squared_error: 594.4967\n",
            "Epoch 48/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 623.0808 - mean_squared_error: 623.0808\n",
            "Epoch 49/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 541.0672 - mean_squared_error: 541.0672\n",
            "Epoch 50/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 590.5519 - mean_squared_error: 590.5519\n",
            "Epoch 51/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 690.0550 - mean_squared_error: 690.0550\n",
            "Epoch 52/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 639.0985 - mean_squared_error: 639.0985\n",
            "Epoch 53/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 721.7224 - mean_squared_error: 721.7224\n",
            "Epoch 54/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 502.7653 - mean_squared_error: 502.7653\n",
            "Epoch 55/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 458.4387 - mean_squared_error: 458.4387\n",
            "Epoch 56/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 499.9461 - mean_squared_error: 499.9461\n",
            "Epoch 57/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 500.1885 - mean_squared_error: 500.1885\n",
            "Epoch 58/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 476.8557 - mean_squared_error: 476.8557\n",
            "Epoch 59/250\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 480.3500 - mean_squared_error: 480.3500\n",
            "Epoch 60/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 463.1577 - mean_squared_error: 463.1577\n",
            "Epoch 61/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 600.5541 - mean_squared_error: 600.5541\n",
            "Epoch 62/250\n",
            "73/73 [==============================] - 0s 3ms/step - loss: 502.0175 - mean_squared_error: 502.0175\n",
            "Epoch 63/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 457.4788 - mean_squared_error: 457.4788\n",
            "Epoch 64/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 461.0522 - mean_squared_error: 461.0522\n",
            "Epoch 65/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 450.7219 - mean_squared_error: 450.7219\n",
            "Epoch 66/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 448.6005 - mean_squared_error: 448.6005\n",
            "Epoch 67/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 531.5192 - mean_squared_error: 531.5192\n",
            "Epoch 68/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 497.4190 - mean_squared_error: 497.4190\n",
            "Epoch 69/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 444.3333 - mean_squared_error: 444.3333\n",
            "Epoch 70/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 494.6123 - mean_squared_error: 494.6123\n",
            "Epoch 71/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 418.8199 - mean_squared_error: 418.8199\n",
            "Epoch 72/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 459.6991 - mean_squared_error: 459.6991\n",
            "Epoch 73/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 481.1876 - mean_squared_error: 481.1876\n",
            "Epoch 74/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 451.3619 - mean_squared_error: 451.3619\n",
            "Epoch 75/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 478.3822 - mean_squared_error: 478.3822\n",
            "Epoch 76/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 477.5590 - mean_squared_error: 477.5590\n",
            "Epoch 77/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 488.3247 - mean_squared_error: 488.3247\n",
            "Epoch 78/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 412.3863 - mean_squared_error: 412.3863\n",
            "Epoch 79/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 420.9297 - mean_squared_error: 420.9297\n",
            "Epoch 80/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 425.1137 - mean_squared_error: 425.1137\n",
            "Epoch 81/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 393.4968 - mean_squared_error: 393.4968\n",
            "Epoch 82/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 571.1353 - mean_squared_error: 571.1353\n",
            "Epoch 83/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 419.3168 - mean_squared_error: 419.3168\n",
            "Epoch 84/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 387.7411 - mean_squared_error: 387.7411\n",
            "Epoch 85/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 462.0930 - mean_squared_error: 462.0930\n",
            "Epoch 86/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 389.1810 - mean_squared_error: 389.1810\n",
            "Epoch 87/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 401.9779 - mean_squared_error: 401.9779\n",
            "Epoch 88/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 434.1746 - mean_squared_error: 434.1746\n",
            "Epoch 89/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 471.1819 - mean_squared_error: 471.1819\n",
            "Epoch 90/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 399.0937 - mean_squared_error: 399.0937\n",
            "Epoch 91/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 436.5583 - mean_squared_error: 436.5583\n",
            "Epoch 92/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 366.2493 - mean_squared_error: 366.2493\n",
            "Epoch 93/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 459.3364 - mean_squared_error: 459.3364\n",
            "Epoch 94/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 409.4361 - mean_squared_error: 409.4361\n",
            "Epoch 95/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 458.9748 - mean_squared_error: 458.9748\n",
            "Epoch 96/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 413.5158 - mean_squared_error: 413.5158\n",
            "Epoch 97/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 425.2468 - mean_squared_error: 425.2468\n",
            "Epoch 98/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 453.6368 - mean_squared_error: 453.6368\n",
            "Epoch 99/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 364.3531 - mean_squared_error: 364.3531\n",
            "Epoch 100/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 399.0859 - mean_squared_error: 399.0859\n",
            "Epoch 101/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 389.6497 - mean_squared_error: 389.6497\n",
            "Epoch 102/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 444.9298 - mean_squared_error: 444.9298\n",
            "Epoch 103/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 404.0992 - mean_squared_error: 404.0992\n",
            "Epoch 104/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 443.9374 - mean_squared_error: 443.9374\n",
            "Epoch 105/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 413.4084 - mean_squared_error: 413.4084\n",
            "Epoch 106/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 312.1878 - mean_squared_error: 312.1878\n",
            "Epoch 107/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 380.7160 - mean_squared_error: 380.7160\n",
            "Epoch 108/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 397.7841 - mean_squared_error: 397.7841\n",
            "Epoch 109/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 372.5612 - mean_squared_error: 372.5612\n",
            "Epoch 110/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 387.1508 - mean_squared_error: 387.1508\n",
            "Epoch 111/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 371.5275 - mean_squared_error: 371.5275\n",
            "Epoch 112/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 367.9489 - mean_squared_error: 367.9489\n",
            "Epoch 113/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 349.3849 - mean_squared_error: 349.3849\n",
            "Epoch 114/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 385.6541 - mean_squared_error: 385.6541\n",
            "Epoch 115/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 430.0315 - mean_squared_error: 430.0315\n",
            "Epoch 116/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 349.7478 - mean_squared_error: 349.7478\n",
            "Epoch 117/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 360.1982 - mean_squared_error: 360.1982\n",
            "Epoch 118/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 394.6611 - mean_squared_error: 394.6611\n",
            "Epoch 119/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 436.5163 - mean_squared_error: 436.5163\n",
            "Epoch 120/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 376.0973 - mean_squared_error: 376.0973\n",
            "Epoch 121/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 369.2621 - mean_squared_error: 369.2621\n",
            "Epoch 122/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 404.0466 - mean_squared_error: 404.0466\n",
            "Epoch 123/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 330.4695 - mean_squared_error: 330.4695\n",
            "Epoch 124/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 373.1655 - mean_squared_error: 373.1655\n",
            "Epoch 125/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 344.4621 - mean_squared_error: 344.4621\n",
            "Epoch 126/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 383.9412 - mean_squared_error: 383.9412\n",
            "Epoch 127/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 400.1354 - mean_squared_error: 400.1354\n",
            "Epoch 128/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 363.9476 - mean_squared_error: 363.9476\n",
            "Epoch 129/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 379.1315 - mean_squared_error: 379.1315\n",
            "Epoch 130/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 315.5446 - mean_squared_error: 315.5446\n",
            "Epoch 131/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 373.4025 - mean_squared_error: 373.4025\n",
            "Epoch 132/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 329.3284 - mean_squared_error: 329.3284\n",
            "Epoch 133/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 353.9850 - mean_squared_error: 353.9850\n",
            "Epoch 134/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 332.1322 - mean_squared_error: 332.1322\n",
            "Epoch 135/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 416.9510 - mean_squared_error: 416.9510\n",
            "Epoch 136/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 420.6421 - mean_squared_error: 420.6421\n",
            "Epoch 137/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 383.2370 - mean_squared_error: 383.2370\n",
            "Epoch 138/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 347.0597 - mean_squared_error: 347.0597\n",
            "Epoch 139/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 355.1047 - mean_squared_error: 355.1047\n",
            "Epoch 140/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 341.5312 - mean_squared_error: 341.5312\n",
            "Epoch 141/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 308.1567 - mean_squared_error: 308.1567\n",
            "Epoch 142/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 328.5283 - mean_squared_error: 328.5283\n",
            "Epoch 143/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 398.7019 - mean_squared_error: 398.7019\n",
            "Epoch 144/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 339.6761 - mean_squared_error: 339.6761\n",
            "Epoch 145/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 313.1854 - mean_squared_error: 313.1854\n",
            "Epoch 146/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 319.9318 - mean_squared_error: 319.9318\n",
            "Epoch 147/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 412.9591 - mean_squared_error: 412.9591\n",
            "Epoch 148/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 322.2807 - mean_squared_error: 322.2807\n",
            "Epoch 149/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 340.3794 - mean_squared_error: 340.3794\n",
            "Epoch 150/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 407.7806 - mean_squared_error: 407.7806\n",
            "Epoch 151/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 357.5679 - mean_squared_error: 357.5679\n",
            "Epoch 152/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 304.4326 - mean_squared_error: 304.4326\n",
            "Epoch 153/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 374.7090 - mean_squared_error: 374.7090\n",
            "Epoch 154/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 352.4689 - mean_squared_error: 352.4689\n",
            "Epoch 155/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 352.9708 - mean_squared_error: 352.9708\n",
            "Epoch 156/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 359.5611 - mean_squared_error: 359.5611\n",
            "Epoch 157/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 357.0083 - mean_squared_error: 357.0083\n",
            "Epoch 158/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 392.1977 - mean_squared_error: 392.1977\n",
            "Epoch 159/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 328.6115 - mean_squared_error: 328.6115\n",
            "Epoch 160/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 362.5464 - mean_squared_error: 362.5464\n",
            "Epoch 161/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 343.7674 - mean_squared_error: 343.7674\n",
            "Epoch 162/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 317.2688 - mean_squared_error: 317.2688\n",
            "Epoch 163/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 350.9849 - mean_squared_error: 350.9849\n",
            "Epoch 164/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 324.3853 - mean_squared_error: 324.3853\n",
            "Epoch 165/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 334.7171 - mean_squared_error: 334.7171\n",
            "Epoch 166/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 351.6280 - mean_squared_error: 351.6280\n",
            "Epoch 167/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 333.8280 - mean_squared_error: 333.8280\n",
            "Epoch 168/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 324.4413 - mean_squared_error: 324.4413\n",
            "Epoch 169/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 351.7323 - mean_squared_error: 351.7323\n",
            "Epoch 170/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 325.9358 - mean_squared_error: 325.9358\n",
            "Epoch 171/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 341.1989 - mean_squared_error: 341.1989\n",
            "Epoch 172/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 348.7667 - mean_squared_error: 348.7667\n",
            "Epoch 173/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 330.2807 - mean_squared_error: 330.2807\n",
            "Epoch 174/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 316.3288 - mean_squared_error: 316.3288\n",
            "Epoch 175/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 317.6479 - mean_squared_error: 317.6479\n",
            "Epoch 176/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 299.8851 - mean_squared_error: 299.8851\n",
            "Epoch 177/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 314.2505 - mean_squared_error: 314.2505\n",
            "Epoch 178/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 311.4160 - mean_squared_error: 311.4160\n",
            "Epoch 179/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 291.8085 - mean_squared_error: 291.8085\n",
            "Epoch 180/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 325.4949 - mean_squared_error: 325.4949\n",
            "Epoch 181/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 348.9172 - mean_squared_error: 348.9172\n",
            "Epoch 182/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 328.7275 - mean_squared_error: 328.7275\n",
            "Epoch 183/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 323.2363 - mean_squared_error: 323.2363\n",
            "Epoch 184/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 300.6672 - mean_squared_error: 300.6672\n",
            "Epoch 185/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 290.2695 - mean_squared_error: 290.2695\n",
            "Epoch 186/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 281.9969 - mean_squared_error: 281.9969\n",
            "Epoch 187/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 287.9704 - mean_squared_error: 287.9704\n",
            "Epoch 188/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 379.6242 - mean_squared_error: 379.6242\n",
            "Epoch 189/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 336.5314 - mean_squared_error: 336.5314\n",
            "Epoch 190/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 392.6621 - mean_squared_error: 392.6621\n",
            "Epoch 191/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 292.6226 - mean_squared_error: 292.6226\n",
            "Epoch 192/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 317.8199 - mean_squared_error: 317.8199\n",
            "Epoch 193/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 320.4931 - mean_squared_error: 320.4931\n",
            "Epoch 194/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 376.8830 - mean_squared_error: 376.8830\n",
            "Epoch 195/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 312.8881 - mean_squared_error: 312.8881\n",
            "Epoch 196/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 340.6207 - mean_squared_error: 340.6207\n",
            "Epoch 197/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 379.8369 - mean_squared_error: 379.8369\n",
            "Epoch 198/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 377.4674 - mean_squared_error: 377.4674\n",
            "Epoch 199/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 308.2423 - mean_squared_error: 308.2423\n",
            "Epoch 200/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 286.9213 - mean_squared_error: 286.9213\n",
            "Epoch 201/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 299.9036 - mean_squared_error: 299.9036\n",
            "Epoch 202/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 311.7941 - mean_squared_error: 311.7941\n",
            "Epoch 203/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 332.8731 - mean_squared_error: 332.8731\n",
            "Epoch 204/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 305.1856 - mean_squared_error: 305.1856\n",
            "Epoch 205/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 278.9840 - mean_squared_error: 278.9840\n",
            "Epoch 206/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 349.7481 - mean_squared_error: 349.7481\n",
            "Epoch 207/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 328.2244 - mean_squared_error: 328.2244\n",
            "Epoch 208/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 332.2064 - mean_squared_error: 332.2064\n",
            "Epoch 209/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 298.4676 - mean_squared_error: 298.4676\n",
            "Epoch 210/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 295.4420 - mean_squared_error: 295.4420\n",
            "Epoch 211/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 349.4665 - mean_squared_error: 349.4665\n",
            "Epoch 212/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 318.1488 - mean_squared_error: 318.1488\n",
            "Epoch 213/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 288.4952 - mean_squared_error: 288.4952\n",
            "Epoch 214/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 315.4926 - mean_squared_error: 315.4926\n",
            "Epoch 215/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 315.2732 - mean_squared_error: 315.2732\n",
            "Epoch 216/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 322.4795 - mean_squared_error: 322.4795\n",
            "Epoch 217/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 374.7342 - mean_squared_error: 374.7342\n",
            "Epoch 218/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 330.7011 - mean_squared_error: 330.7011\n",
            "Epoch 219/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 306.4810 - mean_squared_error: 306.4810\n",
            "Epoch 220/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 321.4941 - mean_squared_error: 321.4941\n",
            "Epoch 221/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 325.6856 - mean_squared_error: 325.6856\n",
            "Epoch 222/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 349.8707 - mean_squared_error: 349.8707\n",
            "Epoch 223/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 308.2746 - mean_squared_error: 308.2746\n",
            "Epoch 224/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 364.9085 - mean_squared_error: 364.9085\n",
            "Epoch 225/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 292.3098 - mean_squared_error: 292.3098\n",
            "Epoch 226/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 302.1905 - mean_squared_error: 302.1905\n",
            "Epoch 227/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 362.2686 - mean_squared_error: 362.2686\n",
            "Epoch 228/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 310.4158 - mean_squared_error: 310.4158\n",
            "Epoch 229/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 317.5935 - mean_squared_error: 317.5935\n",
            "Epoch 230/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 341.5953 - mean_squared_error: 341.5953\n",
            "Epoch 231/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 339.9187 - mean_squared_error: 339.9187\n",
            "Epoch 232/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 285.9129 - mean_squared_error: 285.9129\n",
            "Epoch 233/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 289.0603 - mean_squared_error: 289.0603\n",
            "Epoch 234/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 320.5125 - mean_squared_error: 320.5125\n",
            "Epoch 235/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 312.6505 - mean_squared_error: 312.6505\n",
            "Epoch 236/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 334.4952 - mean_squared_error: 334.4952\n",
            "Epoch 237/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 316.6870 - mean_squared_error: 316.6870\n",
            "Epoch 238/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 299.1289 - mean_squared_error: 299.1289\n",
            "Epoch 239/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 309.2968 - mean_squared_error: 309.2968\n",
            "Epoch 240/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 295.9714 - mean_squared_error: 295.9714\n",
            "Epoch 241/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 287.4258 - mean_squared_error: 287.4258\n",
            "Epoch 242/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 262.4814 - mean_squared_error: 262.4814\n",
            "Epoch 243/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 279.2793 - mean_squared_error: 279.2793\n",
            "Epoch 244/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 345.9653 - mean_squared_error: 345.9653\n",
            "Epoch 245/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 318.9187 - mean_squared_error: 318.9187\n",
            "Epoch 246/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 303.4087 - mean_squared_error: 303.4087\n",
            "Epoch 247/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 302.7979 - mean_squared_error: 302.7979\n",
            "Epoch 248/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 314.9064 - mean_squared_error: 314.9064\n",
            "Epoch 249/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 283.2636 - mean_squared_error: 283.2636\n",
            "Epoch 250/250\n",
            "73/73 [==============================] - 0s 2ms/step - loss: 315.3228 - mean_squared_error: 315.3228\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0e612a2860>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qc6-jQIzaBUT"
      },
      "source": [
        "pred2 = model.predict(test2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIgmlt7Iancb"
      },
      "source": [
        "Prediction2 = pd.DataFrame(pred2 , columns = [\"Total No of TB Cases\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HCuYtwga3UV"
      },
      "source": [
        "ANN_Output = pd.concat([pp , Prediction2] , axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkaj8lOha-jC"
      },
      "source": [
        "ANN_Output.to_csv(\"ANN_Output.csv\" , index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycXyDYgKbRgV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "b7731b83-3d03-46e6-c5ed-68ad60b71202"
      },
      "source": [
        "files.download(\"ANN_Output.csv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_c2c46df4-ee71-4e35-96ea-660ccbae5936\", \"ANN_Output.csv\", 48501)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9q2BL5DJbiz6"
      },
      "source": [
        "import tensorflow_probability as tfp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79FuT93-ctnt"
      },
      "source": [
        "tfd = tfp.distributions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hK9YGhsFkiF_"
      },
      "source": [
        "import tensorflow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ws7Ae8NXmN0h"
      },
      "source": [
        "from keras.layers import GlobalAveragePooling2D"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ht7It3dUm_WE"
      },
      "source": [
        "from keras.layers import BatchNormalization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17gZpJDgnb00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 776
        },
        "outputId": "f0b4cdc7-617d-474a-e82d-fa87d2e5c011"
      },
      "source": [
        "pip install fastai"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fastai in /usr/local/lib/python3.6/dist-packages (1.0.61)\n",
            "Requirement already satisfied: fastprogress>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from fastai) (1.0.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from fastai) (0.7.0+cu101)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from fastai) (1.18.5)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from fastai) (4.6.3)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.6/dist-packages (from fastai) (2.7.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from fastai) (2.23.0)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from fastai) (1.6.0+cu101)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from fastai) (3.2.2)\n",
            "Requirement already satisfied: spacy>=2.0.18; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from fastai) (2.2.4)\n",
            "Requirement already satisfied: bottleneck in /usr/local/lib/python3.6/dist-packages (from fastai) (1.3.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from fastai) (3.13)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from fastai) (20.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from fastai) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from fastai) (1.1.2)\n",
            "Requirement already satisfied: nvidia-ml-py3 in /usr/local/lib/python3.6/dist-packages (from fastai) (7.352.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from fastai) (7.0.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from fastai) (0.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (2020.6.20)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->fastai) (0.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (2.4.7)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (2.0.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (0.4.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (1.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (0.8.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (1.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (50.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (4.41.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (1.0.2)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (1.1.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (3.0.2)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.0.18; python_version < \"3.8\"->fastai) (7.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->fastai) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->fastai) (2018.9)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.0.18; python_version < \"3.8\"->fastai) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.0.18; python_version < \"3.8\"->fastai) (3.2.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1x3LT99qf5v"
      },
      "source": [
        "from fastai.tabular import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuO12NNTqn2U"
      },
      "source": [
        "fastX = (TabularList(X))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VU7ns4N7q1R7"
      },
      "source": [
        "fasty = (TabularList(y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpCd2fMQq5eb"
      },
      "source": [
        "fasttest = (TabularList(test2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mybEo7TJq9OP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "outputId": "0540a198-5bcb-4c7d-d1d8-1c1c97ad0ab4"
      },
      "source": [
        "learn = tabular_learner(X, layers=[300,200, 100, 50], metrics= [rmse,r2_score])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-93-6cab65d24d7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtabular_learner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrmse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr2_score\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/tabular/learner.py\u001b[0m in \u001b[0;36mtabular_learner\u001b[0;34m(data, layers, emb_szs, metrics, ps, emb_drop, y_range, use_bn, **learn_kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m         ps:Collection[float]=None, emb_drop:float=0., y_range:OptRange=None, use_bn:bool=True, **learn_kwargs):\n\u001b[1;32m     14\u001b[0m     \u001b[0;34m\"Get a `Learner` using `data`, with `metrics`, including a `TabularModel` created using the remaining params.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0memb_szs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_emb_szs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mifnone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb_szs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     model = TabularModel(emb_szs, len(data.cont_names), out_sz=data.c, layers=layers, ps=ps, emb_drop=emb_drop,\n\u001b[1;32m     17\u001b[0m                          y_range=y_range, use_bn=use_bn)\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5134\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5135\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5136\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5138\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'get_emb_szs'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOObaoJ7rGXq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}